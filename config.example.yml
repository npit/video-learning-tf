run:
  # run type and an identifier for it
  workflow: defs.workflows.imgdesc.statebias
  # save / load configuration
  resume_file: 
  # folder to store run data
  run_folder: "path/to/outputfolder"
  phase : defs.phase.val

  # data parameters; a list of input data 
  data:
    data_source_1:
      data_path: "path/to/data"
      prepend_folder: ""
      raw_image_shape: (240, 320, 3)
      image_shape: (227, 227, 3)
      mean_image: [103.939, 116.779, 123.68]
      data_format: defs.data_format.tfrecord
      frame_format: "jpg"
      imgproc: []
      batch_item: defs.batch_item.default
      phase: defs.phase.train
      tag: defs.dataset_tag.main
      image_tries: 3
    # similarly, can define additional datasets

  network:
    # architecture settings
    image_shape: (227, 227, 3)
    frame_encoding_layer: "fc7"
    lstm_params: [200, 3, defs.fusion_method.last]
    frame_fusion : [defs.fusion_type.early, defs.fusion_method.last]
    clip_fusion : [defs.fusion_type.late, defs.fusion_method.last]
    num_classes : 101
    # dataset fusion method, dataset fusion method, pre-workflow frame fusion method. Skip last arg if no framefusion.
    dataset_fusion: [defs.fusion_type.late, defs.fusion_method.avg, defs.fusion_method.avg]
    multi_workflow: defs.workflow.lstm
    load_weights: True

  # phase settings
  train:
    # training settings
    batch_size: 1
    epochs : 2
    optimizer : defs.optim.sgd
    base_lr: 0.1
    lr_mult : None
    lr_decay : [ defs.decay.granularity.exp, defs.decay.scheme.interval, 8, 0.96 ]
    #clip_grads : (-1.,1.)
    clip_grads : None
    clip_norm : 5
    #clip_grads : None
    dropout_keep_prob : 0.5

  val:
    # validation settings
    batch_size: 2
    interval: [defs.]
    logits_save_interval : -1


  logging:
    # logging
    save_freq_per_epoch : 0.5
    level : logging.DEBUG
    print_tensors : False
    tensorboard_folder : "tensorboard"



  # imgdesc vars
  captioning:
    caption_search : defs.caption_search.max
    eval_type : defs.eval_type.coco
    caption_ground_truth : "path/to/caption/gt"
    word_embeddings_file : "path/to/embeddings"

serialize:

  # path to prepend to each image path
  path_prepend_folder: "path/to/images/folder"

  # video / image list to serialize
  input_files: [ "/path/to/imgfile1", "/path/to/imgfile2"]

  # run type
  run_id: ""
  seed: 1936
  do_shuffle: True
  do_serialize: True
  do_validate: True
  validate_pcnt: 10
  num_threads: 2
  num_items_per_thread: 20
  run_id: None

  output_folder: "path/to/output/folder/" 
  generation_error: defs.generation_error.compromise

  # video frames generation parameters 
  clip_offset_or_num: 2
  num_frames_per_clip: 16
  raw_image_shape: (240,320,3)
  clipframe_mode: defs.clipframe_mode.iterative
  frame_format: "jpg"

  logging_level : logging.INFO

captions:
  # vocabulary to encode captions or produce embeddings.Set to None to generate.
  vocabulary_file: None
  # caption files to encode or to generate vocabulary
  caption_files:  ["/path/to/captionfile1","/path/to/captionfile2"]
  caption_file_formats: ["coco","flickr"]
  vocab_replacement_file: None
  word_count_thresh: 5
  caption_max_length: 50
  randomize_missing_embeddings: False

  # embedding generation files
  embeddings_file: "/path/to/embedding/matrix"
  embeddings_file_type: "glove"
